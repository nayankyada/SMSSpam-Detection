# -*- coding: utf-8 -*-
"""SpamDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mkv2frovjceAXN9wt65uDd7Nrhv1hnf7
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import string
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
from gensim.models import Word2Vec
from gensim.models import KeyedVectors
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score,confusion_matrix
from sklearn.preprocessing import LabelEncoder
from keras.models import Model
from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding
from keras.optimizers import RMSprop
from keras.preprocessing.text import Tokenizer
from keras.preprocessing import sequence
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping
from keras.models import Sequential

"""# Data Loading"""

data = pd.read_csv('/content/drive/My Drive/3_SPAM detection/a.csv')
data = data[['v1','v2']] # v1-Classlabel,v2-Text

print('No of DataPoint',data.shape[0])
print('\nNo of dataPoint for each class\n',data['v1'].value_counts())
total_datapoint = data.shape[0]
ham_datapoint = data[data['v1'] == 'ham'].shape[0]
spam_datapoint = data[data['v1'] == 'spam'].shape[0]
print('\nPercentage of ham datapoint is : ',ham_datapoint/total_datapoint * 100)
print('Percentage of spam datapoint is : ',spam_datapoint/total_datapoint * 100)

data.head()

"""# Basic EDA of Data"""

# Count plot according classs label
sns.countplot(data.v1)

"""1. There are large no of ham text as compared  to spam text which leads to imbalance data sets."""

# Count no od word in text
def text_length(row):
    return len(row.split(" "))
data['text_length'] = data['v2'].apply(lambda row : text_length(row))

sns.FacetGrid(data,hue='v1',height=5).map(sns.distplot,'text_length').add_legend()

"""1. Spam text with large text length as compare to ham"""

#count punctuation percent in text
print('Punctuation symbole are : ',string.punctuation)
def punc_percent(row):
    c = sum([1 for char in row if char in string.punctuation])
    return (round(c/len(row),3)*100)
data['punc%'] = data['v2'].apply(lambda x : punc_percent(x))

sns.FacetGrid(data,hue='v1',height=5).map(sns.distplot,'punc%').add_legend()

"""1. punc% for spam text and ham text almost same but for some ham text punc% large compare to ham text
2. PDF of spam text is high means most of spam text puc% are at 4-6

# Data Preprocessing

<h4><b>1.1 Remove punctuation
"""

def remove_punctu(row):
    row_nonpunct = "".join([char for char in row if char not in string.punctuation])
    return row_nonpunct

"""<h4><b>1.2 Decontracted"""

import re
def decontracted(phrase):
    phrase = re.sub(r"won't", "will not", phrase)
    phrase = re.sub(r"can\'t", "can not", phrase)
    phrase = re.sub(r"n\'t", " not", phrase)
    phrase = re.sub(r"\'re", " are", phrase)
    phrase = re.sub(r"\'s", " is", phrase)
    phrase = re.sub(r"\'d", " would", phrase)
    phrase = re.sub(r"\'ll", " will", phrase)
    phrase = re.sub(r"\'t", " not", phrase)
    phrase = re.sub(r"\'ve", " have", phrase)
    phrase = re.sub(r"\'m", " am", phrase)
    return phrase

"""<h4><b>1.3 Remove word with number"""

def remove_numword(row):
    return re.sub("\S*\d\S*", "", row).strip()

"""<h4><b>1.4 Remove spacial character"""

def remove_special_char(row):
    return re.sub('[^A-Za-z0-9]+', ' ', row)

"""<h4><b>1.5 Remove stop word"""

import nltk
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.corpus import stopwords
stopword = stopwords.words('english')
print(stopword)
def remove_stopword(row):
    return(" ".join([char for char in row.split(" ") if char not in stopword]))

"""<h1><b>Preprocessing"""

preprocessed_reviews = []
for sentance in data['v2'].values:
    sentance = remove_punctu(sentance)
    sentance = decontracted(sentance)
    sentance = remove_numword(sentance)
    sentance = remove_special_char(sentance)
    sentance = remove_stopword(sentance)
    sentance = ' '.join(e.lower() for e in sentance.split())
    preprocessed_reviews.append(sentance.strip())

i=0
list_of_sentance=[]
for sentance in preprocessed_reviews:
    list_of_sentance.append(sentance.split())

"""# Word2Vec model and prepare data for training and test"""

# min_count = 5 considers only words that occured atleast 5 times
# size=100 means it use top 100 words which are occured atleast 5 time
w2v_model=Word2Vec(list_of_sentance,min_count=5,size=100, workers=4)
w2v_words = list(w2v_model.wv.vocab)
print("number of words that occured minimum 5 times ",len(w2v_words))
print("sample words ", w2v_words[0:50])

"""tfidf = tf * idf
1. tf = no of time word w_i in text t_j / total word in t_j
2. idf = log(total text / no of text which contains word w_i)
"""

model = TfidfVectorizer()
tf_idf_matrix = model.fit_transform(preprocessed_reviews)
# we are converting a dictionary with word as a key, and the idf as a value
dictionary = dict(zip(model.get_feature_names(), list(model.idf_)))

tfidf_feat = model.get_feature_names() # tfidf words/col-names
tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list
row=0;
for sent in (list_of_sentance): # for each review/sentence 
    sent_vec = np.zeros(100) # as word vectors are of zero length
    weight_sum =0; # num of words with a valid vector in the sentence/review
    for word in sent: # for each word in a review/sentence
        if word in w2v_words and word in tfidf_feat:
            vec = w2v_model.wv[word]
            tf_idf = (sent.count(word)/len(sent))*dictionary[word]
            sent_vec += (vec * tf_idf)
            weight_sum += tf_idf
    if weight_sum != 0:
        sent_vec /= weight_sum
    tfidf_sent_vectors.append(sent_vec)
    row += 1

feature = np.array(tfidf_sent_vectors)
print(feature.shape)
feature=np.vstack((feature.T,np.array(data['text_length']).T)).T
feature=np.vstack((feature.T,np.array(data['punc%']).T)).T
print(feature.shape)

x = feature
y = data['v1']
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)
print('No of train data pioint : ',x_train.shape)
print('No of test data pioint : ',x_test.shape)
print('\nNo of ham and spam datapoint in train data : \n',y_train.value_counts())
print('\nNo of ham and spam datapoint in test data :  \n',y_test.value_counts())

"""# ML : Logistic Regression"""

from sklearn.linear_model import LogisticRegression
tuned_parameters =  [{'C': [10**-4, 10**-2, 10**0, 10**4]}]
model = GridSearchCV(LogisticRegression(solver='liblinear'), tuned_parameters, scoring = 'accuracy', cv=10)
model.fit(x_train, y_train)
print(model.best_estimator_)
print('Score : ',model.score(x_test, y_test))
y_pred = model.predict(x_test)
print(confusion_matrix(y_test,y_pred,labels=['ham','spam']))
cm=confusion_matrix(y_test,y_pred,labels=['ham','spam'])
ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax,); #annot=True to annotate cells
ax.set_xlabel('Predicted labels');
ax.set_ylabel('True labels'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['ham', 'spam']); 
ax.yaxis.set_ticklabels(['ham', 'spam']);

"""model perform best on ham as compare to spam duto lake of less no data point of spam text

# ML : Random Forest
"""

params = {'n_estimators':[20,45,80,100],'max_depth':[10,15,20]}
clf = RandomForestClassifier()
model = GridSearchCV(clf,params)
history=model.fit(x_train,y_train)
print(model.best_estimator_)
print('Score : ',model.score(x_test, y_test))
y_pred = model.predict(x_test)
print(confusion_matrix(y_test,y_pred,labels=['ham','spam']))
cm=confusion_matrix(y_test,y_pred,labels=['ham','spam'])
ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax,); #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted labels');
ax.set_ylabel('True labels'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['ham', 'spam']); 
ax.yaxis.set_ticklabels(['ham', 'spam']);

"""Random forest perform best compare to Logistic Regression

# Deep Learning - LSTM
"""

from sklearn.preprocessing import LabelEncoder # to encode class label name in 0 to no of class

text = data['v2']
label = data['v1']
le = LabelEncoder()
label = le.fit_transform(label)
label = label.reshape(-1,1)

"""Here we train data based on batch size and each text are of different length so we need to make all text of same lenth because all text in batch should be same laength so we need to do some padding sequence"""

max_words = 1000  # like vocabulary size
max_len = 150
tok = Tokenizer(num_words=max_words) # num_word define number of word to be consider based on word frequency
                                     # so it consider mostly occured 1000 words and create dictionary of word 
tok.fit_on_texts(text) # takes data courpus and create dictionary of word 
sequences = tok.texts_to_sequences(text) # now it replace each word with dictionary word index
print(sequences[0:5])
sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len) #it convert each sms of same length because here each sms length are different
print(sequences_matrix[0])  
X_train,X_test,Y_train,Y_test = train_test_split(sequences_matrix,label,test_size=0.15)

batch_size=512
model = Sequential()
model.add(Embedding(max_words,60,input_length=max_len)) # 60 define output dim
                                                      # maxwords define the largest integer (i.e. word index) in the input should be
                                                      # no larger than 999 (vocabulary size)
model.add(LSTM(100))
model.add(Dense(256,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])
model.fit(X_train,Y_train,batch_size=512,epochs=10,validation_split=0.2)

print(model.evaluate(X_test,Y_test))
Y_pred = model.predict_classes(X_test)
print(confusion_matrix(Y_test,Y_pred))
cm=confusion_matrix(Y_test,Y_pred)
ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax,); #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted labels');
ax.set_ylabel('True labels'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['ham', 'spam']); 
ax.yaxis.set_ticklabels(['ham', 'spam']);

"""LSTM perform best compare to Random Forest

# Conclusion
1. LogisticRegression gives 96.41% accuracy on test data
2. RandomForest gives 97.57% accuracy on test data
3. LSTM deep learning gives 99.40% accuracy on test data
"""